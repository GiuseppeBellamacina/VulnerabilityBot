from chains import CyberChain
from langchain_ollama import OllamaLLM
from utilities import load_config
import asyncio
import threading
import httpx
from quart import Quart, request, jsonify
import uvicorn

app = Quart(__name__)
threads_lock = threading.Lock()
threads = []

async def send_response(data, url):
    try:
        print("\33[1;35m[AI]\33[0m: Sending responses of requests with id:", [d['id'] for d in data], 
              ", analysis_id:", set([d['analysis_id'] for d in data]))
        async with httpx.AsyncClient(verify=False) as client:
            print("Data:", data)
            response = await client.post(url, json=data)
            response.raise_for_status()
            print(f"Response: {response}")
            return response
    except httpx.RequestError as e:
        print(f"Request error: {e}")
        return e
    except httpx.HTTPStatusError as e:
        print(f"HTTP status error: {e}")
        return e

def process_data(data, url):
    try:
        print("\33[1;35m[AI]\33[0m: Processing requests with id:", [d["id"] for d in data], 
              ", analysis_id:", set([d["analysis_id"] for d in data]))
        response = chain.batch(data)
        asyncio.run(send_response(response, url))
    except Exception as e:
        print(f"Error in processing data: {e}")
    finally:
        with threads_lock:
            threads.pop(0)  # Remove thread from the list after it completes

@app.route('/ai', methods=['POST'])
async def ai():
    try:
        data = await request.get_json()
        print("\33[1;35m[AI]\33[0m: Received queries:", [d['id'] for d in data])
        db_url = config['urls']['db']
        thread = threading.Thread(target=process_data, args=(data, db_url + '/db/update'), daemon=True)
        with threads_lock:
            threads.append(thread)
        thread.start()
        return jsonify({'status': 'success'})
    except Exception as e:
        print(f"Error in /ai endpoint: {e}")
        return jsonify({'status': 'error'})

config = load_config("config.yaml")
llm = OllamaLLM(
    model=config['model']['name'],
    base_url=config['model']['base_url'],
    temperature=config['model']['temperature'],
    num_predict=config['model']['num_predict']
)
chain = CyberChain(llm)

@app.after_serving
async def shutdown():
    with threads_lock:
        for thread in threads:
            thread.join()

if __name__ == '__main__':
    uvicorn.run(app, host='0.0.0.0', port=8000, ssl_keyfile=config['paths']['key'], ssl_certfile=config['paths']['cert'])
